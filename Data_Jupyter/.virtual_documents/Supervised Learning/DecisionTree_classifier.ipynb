import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split


titanic = sns.load_dataset("titanic")


titanic.head
titanic.isnull().sum()


features = ["pclass","sex","fare","embarked","age"]
target = ["survived"]


#missing data

from sklearn.impute import SimpleImputer

imp_median = SimpleImputer(strategy="median")
titanic[["age"]] = imp_median.fit_transform(titanic[["age"]])

imp_freq = SimpleImputer(strategy="most_frequent")
titanic[["embarked"]] = imp_freq.fit_transform(titanic[["embarked"]])



 #encode

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

titanic["sex"] = le.fit_transform(titanic["sex"])
titanic["embarked"] = le.fit_transform(titanic["embarked"])


X = titanic[features]
y = titanic[target]


X_train, X_test, y_train, y_test=train_test_split(
    X,y, test_size=0.2,random_state=42
)


#without Pruning

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train,y_train)


from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)

print("Accuracy : ",accuracy_score(y_test,y_pred))






max_depth = [2,3,4,5,6,7,8,9,10]

for depth in max_depth:
    model = DecisionTreeClassifier(max_depth=depth)
    model.fit(X_train,y_train)

    acc = model.score(X_test,y_test)
    print(f"For depth={depth}, accuracy={acc}")





full_tree = DecisionTreeClassifier(random_state=42)
full_tree.fit(X_train,y_train)


path = full_tree.cost_complexity_pruning_path(X_train,y_train)
ccp_alphas = path.ccp_alphas
print(ccp_alphas)


#train our model for all alphas

trees = []

for alpha in ccp_alphas:
    model = DecisionTreeClassifier(random_state=42,ccp_alpha=alpha)
    model.fit(X_train,y_train)

    trees.append((model,alpha))


best_acc = 0
best_alpha = 0

for model,alpha in trees:
    curr_acc = model.score(X_test,y_test)
    if curr_acc > best_acc:
        best_acc=curr_acc
        best_alpha = alpha


best_acc
