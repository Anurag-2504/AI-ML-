import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


df = pd.read_csv("loan_approval_data.csv")


df.head()
# df.info()
# df.describe()





catergorial_cols=df.select_dtypes(include=["object"]).columns
numerical_cols=df.select_dtypes(include=["number"]).columns


from sklearn.impute import SimpleImputer

num_imp = SimpleImputer(strategy="mean")
df[numerical_cols] = num_imp.fit_transform(df[numerical_cols])

cat_imp = SimpleImputer(strategy="most_frequent")
df[catergorial_cols] = cat_imp.fit_transform(df[catergorial_cols])



df.head()






#Checking how balanced our class are?

classes_count = df["Loan_Approved"].value_counts()
plt.pie(classes_count,labels=["No","Yes"],autopct="%1.1f%%")
plt.title("Is loan approved or not")


#analyze Categories

# gender_cnt = df["Gender"].value_counts()
# ax = sns.barplot(gender_cnt)
# ax.bar_label(ax.containers[0])

edu_cnt = df["Education_Level"].value_counts()
ax = sns.barplot(edu_cnt)
ax.bar_label(ax.containers[0])





from sklearn.preprocessing import LabelEncoder, OneHotEncoder

le = LabelEncoder()
df["Education_Level"]=le.fit_transform(df["Education_Level"])
df["Loan_Approved"]=le.fit_transform(df["Loan_Approved"])



df.head()


cols=["Employment_Status","Marital_Status","Loan_Purpose","Property_Area","Gender","Employer_Category"]

ohe= OneHotEncoder(drop="first",sparse_output=False, handle_unknown="ignore")

encoded = ohe.fit_transform(df[cols])

encoded_df =pd.DataFrame(encoded, columns=ohe.get_feature_names_out(cols),index=df.index)

df = pd.concat([df.drop(columns=cols),encoded_df],axis=1)


df.head()





num_cols = df.select_dtypes(include="number")
corr_matrix= num_cols.corr()

plt.figure(figsize=(15,8))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm"
)


num_cols.corr()["Loan_Approved"].sort_values(ascending=False)





X=df.drop("Loan_Approved",axis=1)
y=df["Loan_Approved"]


X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)


from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)





#Logistic Regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

log_model=LogisticRegression()
log_model.fit(X_train_scaled,y_train)
y_pred=log_model.predict(X_test_scaled)

#Evaluation

print("Logistic Regression")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))


# KNn algorithm

from sklearn.neighbors import KNeighborsClassifier

knn_model=KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled,y_train)
y_pred=knn_model.predict(X_test_scaled)

#Evaluation

print("KNn")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))


#naive bayes

from sklearn.naive_bayes import GaussianNB

nb_model=GaussianNB()
nb_model.fit(X_train_scaled,y_train)
y_pred=nb_model.predict(X_test_scaled)

#Evaluation

print("Naive Bayes")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))








#Add or Transform features

df["DTI_Ratio_sq"] = df["DTI_Ratio"]**2
df["Credit_Score_sq"]=df["Credit_Score"]**2

df["Applicant_Income_log"] = np.log1p(df["Applicant_Income"])

X=df.drop(columns=["Loan_Approved","Credit_Score","DTI_Ratio"])
y=df["Loan_Approved"]

#Train Test Split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

#scaling
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


#Logistic Regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

log_model=LogisticRegression()
log_model.fit(X_train_scaled,y_train)
y_pred=log_model.predict(X_test_scaled)

#Evaluation

print("Logistic Regression")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))


# KNn algorithm

from sklearn.neighbors import KNeighborsClassifier

knn_model=KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled,y_train)
y_pred=knn_model.predict(X_test_scaled)

#Evaluation

print("KNn")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))


#naive bayes

from sklearn.naive_bayes import GaussianNB

nb_model=GaussianNB()
nb_model.fit(X_train_scaled,y_train)
y_pred=nb_model.predict(X_test_scaled)

#Evaluation

print("Naive Bayes")
print("Recall score : ",recall_score(y_test,y_pred))
print("Accuracy score : ",accuracy_score(y_test,y_pred))
print("Precision score : ",precision_score(y_test,y_pred))
print("F1 score : ",f1_score(y_test,y_pred))
print("Confusion matrix : ",confusion_matrix(y_test,y_pred))






